#!/bin/bash

set -euo pipefail

echo "ğŸš€ Starting Web Crawler Infrastructure..."
echo "========================================"

# Create necessary directories
mkdir -p crawled_data

# Stop any existing containers
echo "ğŸ›‘ Stopping existing containers..."
docker-compose down --remove-orphans

# Build and start all services in detached mode
echo "ğŸ”¨ Building and starting services..."
docker-compose up --build -d

# Wait for services to be ready
echo "â³ Waiting for services to be ready..."
sleep 10

echo "âœ… All services started successfully!"
echo ""
echo "ğŸ¯ Web Crawler is now running in controlled mode:"
echo "   â€¢ Workers are connected to Kafka queues and waiting"
echo "   â€¢ Master is in standby mode"
echo "   â€¢ No crawling has started yet"
echo ""
echo "ğŸ“‹ Available commands:"
echo "   python3 main.py start          # Start crawling with seed URLs"
echo "   python3 main.py health_check   # Check system health"
echo "   python3 main.py stop           # Get instructions to stop"
echo ""
echo "ğŸ“Š To view logs from all services:"
echo "   docker-compose logs -f"
echo ""
echo "ğŸ“Š To view logs from specific service:"
echo "   docker-compose logs -f <service-name>"
echo "   Available services: master, worker-1, worker-2, worker-3, worker-4, worker-5, kafka, mongodb"
echo ""
echo "ğŸ›‘ To stop all services:"
echo "   docker-compose down"
echo ""
echo "ğŸ—‘ï¸  To stop and remove all data:"
echo "   docker-compose down -v"
